---
title: "DSC3216_Project_R_FullData_Finalised"
author: "Eng Jing Min, Belinda, Eugenia Wong Shu Shan, Goh Jie Da, Quek Wei Liang,
  Quek Yew Hong, Ryan & Te(Ting) Sze Ying\v"
date: "4/13/2019"
output: 
  html_document:
    toc: yes
---

#Source Data
```{r}
library(readr)
Feature_reduction_normalised <- read_csv("C:/Users/Quek Wei Liang/OneDrive/Documents/National University of Singapore/AY2018-19 Year 3 Semester 2/DSC3216 Predictive Analytics in Business/Projects/Data/Feature_reduction_normalised.csv")
head(Feature_reduction_normalised)
```

#Exclude image_name column from dataset
```{r}
library(dplyr)
Feature_reduction_normalised = select(Feature_reduction_normalised, -image_name)
```

#Dataset
```{r}
names(Feature_reduction_normalised)
head(Feature_reduction_normalised)
summary(Feature_reduction_normalised)
```

#Create random samples
```{r}
set.seed(123)
train_sample <- sample(nrow(Feature_reduction_normalised),nrow(Feature_reduction_normalised)*0.7)
str(train_sample)
print(train_sample)
trainData <- Feature_reduction_normalised [train_sample,]
testData <- Feature_reduction_normalised [-train_sample,]
```

#Logistic Regression
```{r}
require(foreign)
require(nnet)
require(ggplot2)
require(reshape2)
require(ISLR)
library(caret)
library(e1071)
facial_logreg <- glm(label ~., data = trainData, family = binomial, control = list(maxit = 50))
summary(facial_logreg)
trainPred_logreg <- predict(facial_logreg, newdata = trainData, type = 'response')
logsregPred_train <- ifelse(trainPred_logreg > 0.5,1,0)
confusionMatrix(table(logsregPred_train, trainData$label))
testPred_logreg <- predict(facial_logreg, newdata = testData, type = 'response')
logsregPred_test <- ifelse(testPred_logreg > 0.5,1,0)
confusionMatrix(table(logsregPred_test, testData$label))
```

#Classification Tree 
```{r}
library(party)
trainData$label <- as.factor(trainData$label)
facial_ctree_train <- ctree(label ~ ., data = trainData)
print(facial_ctree_train)
plot(facial_ctree_train, type = 'simple')
plot(facial_ctree_train)
print(facial_ctree_train)
confusionMatrix(table(predict(facial_ctree_train), trainData$label))
testData$label <- as.factor(testData$label)
facial_ctree_test <- ctree(label ~ ., data = testData)
plot(facial_ctree_test, type = 'simple')
plot(facial_ctree_test)
print(facial_ctree_test)
confusionMatrix(table(predict(facial_ctree_test), testData$label))
```

#Support Vector Machine (SVM)
####Linear Support Vector Machine
```{r}
library(e1071)
library(gmodels)

svm_classifier_linear = svm(formula = label~., data = trainData, type= "C-classification", kernel = "linear")
svm_classifier_linear
confusionMatrix(table(predict(svm_classifier_linear), trainData$label))

svm_pred_linear = predict(svm_classifier_linear, newdata= testData)
table(svm_pred_linear, testData$label)
CrossTable(testData$label,svm_pred_linear,prop.chisq= FALSE, prop.c= FALSE, prop.r = FALSE)
confusionMatrix(table(svm_pred_linear, testData$label), mode = "prec_recall", positive = "1")
```

#### Radial Support Vector Machine (best option)
```{r}
svm_classifier_radial = svm(formula = label~., data = trainData, type= "C-classification", kernel = "radial")
svm_classifier_radial
confusionMatrix(table(predict(svm_classifier_radial), trainData$label))

svm_classifier_radial = svm(formula = label~., data = trainData, type= "C-classification", kernel = "radial")
svm_pred_radial = predict(svm_classifier_radial, newdata= testData)
table(svm_pred_radial, testData$label)
CrossTable(testData$label,svm_pred_radial,prop.chisq= FALSE, prop.c= FALSE, prop.r = FALSE)
confusionMatrix(table(svm_pred_radial, testData$label), mode = "prec_recall", positive = "1")
```

####Sigmoid Support Vector Machine
```{r}
svm_classifier_sigmoid = svm(formula = label~., data = trainData, type= "C-classification", kernel = "sigmoid")
svm_classifier_sigmoid
confusionMatrix(table(predict(svm_classifier_sigmoid), trainData$label))

svm_classifier_sigmoid = svm(formula = label~., data = trainData, type= "C-classification", kernel = "sigmoid")
svm_pred_sigmoid = predict(svm_classifier_sigmoid, newdata= testData)
table(svm_pred_sigmoid , testData$label)
CrossTable(testData$label,svm_pred_sigmoid ,prop.chisq= FALSE, prop.c= FALSE, prop.r = FALSE)
confusionMatrix(table(svm_pred_sigmoid, testData$label), mode = "prec_recall", positive = "1")
```

#F1-score
####F1-score (Logistic Regression)
```{r}
library(MLmetrics)
facial_logreg <- glm(label ~., data = trainData, family = binomial, control = list(maxit = 50))
trainPred_logreg <- predict(facial_logreg, newdata = trainData, type = 'response')
logsregPred_train <- ifelse(trainPred_logreg > 0.5,1,0)
F1_Score(y_pred = logsregPred_train, y_true = trainData$label)

testPred_logreg <- predict(facial_logreg, newdata = testData, type = 'response')
logsregPred_test <- ifelse(testPred_logreg > 0.5,1,0)
F1_Score(y_pred = logsregPred_test, y_true = testData$label)
```

####F1-score (Classification Tree)
```{r}
precision_ctree = (table(predict(facial_ctree_train), trainData$label)[2, "1"])/(table(predict(facial_ctree_train), trainData$label)[2, "1"]+table(predict(facial_ctree_train), trainData$label)[2, "0"])
recall_ctree = (table(predict(facial_ctree_train), trainData$label)[2, "1"])/((table(predict(facial_ctree_train), trainData$label)[2, "1"])+(table(predict(facial_ctree_train), trainData$label)[1, "1"]))

F1_ctree_train <- ( 2* precision_ctree * recall_ctree) / (precision_ctree + recall_ctree)
F1_ctree_train


precision_ctree = (table(predict(facial_ctree_test), testData$label)[2, "1"])/(table(predict(facial_ctree_test), testData$label)[2, "1"]+table(predict(facial_ctree_test), testData$label)[2, "0"])
recall_ctree = (table(predict(facial_ctree_test), testData$label)[2, "1"])/((table(predict(facial_ctree_test), testData$label)[2, "1"])+(table(predict(facial_ctree_test), testData$label)[1, "1"]))

F1_ctree_test <- ( 2* precision_ctree * recall_ctree) / (precision_ctree + recall_ctree)
F1_ctree_test
```

####F1-score (Support Vector Machine - Radial kernel)
```{r}
library(caret)
x <- trainData$label
x.factor <- factor(x)
predictions_svm_train <- svm_pred_radial 
predictions.factor_svm_train <- factor(predictions_svm_train)
precision_svm_train <- posPredValue(predictions.factor_svm_train, x.factor, positive="1")
recall_svm_train <- sensitivity(predictions.factor_svm_train,x.factor, positive="1")
F1_svm_train <- ( 2* precision_svm_train * recall_svm_train) / (precision_svm_train + recall_svm_train)
F1_svm_train

y <- testData$label
y.factor <- factor(y)
predictions_svm <- svm_pred_radial 
predictions.factor_svm <- factor(predictions_svm)
precision_svm <- posPredValue(predictions.factor_svm, y.factor, positive="1")
recall_svm <- sensitivity(predictions.factor_svm,y.factor, positive="1")
F1_svm_test <- ( 2* precision_svm * recall_svm) / (precision_svm + recall_svm)
F1_svm_test
```

#ROC curve
```{r}
library(ggplot2)
library(ROCR)

logreg_ROC <- glm(label~., data=Feature_reduction_normalised, family="binomial")
pred_logreg_1 <- prediction(predict(logreg_ROC), Feature_reduction_normalised$label)
perf_logreg_ROC <- performance(pred_logreg_1,"tpr","fpr")
ctree_ROC <- ctree(label ~ ., data = Feature_reduction_normalised)
pred_ctree_2 <- prediction(predict(ctree_ROC), Feature_reduction_normalised$label)
perf_ctree_ROC <- performance(pred_ctree_2,"tpr","fpr")
svm_ROC <- svm(formula = label~., data = Feature_reduction_normalised, type= "C-classification", kernel = "radial")
predict_svm <- predict(svm_ROC, type = 'response')
predict_svm
pred_svm_3 <- prediction(as.numeric(predict_svm), as.numeric(Feature_reduction_normalised$label))
perf_svm_ROC <- performance(pred_svm_3, 'tpr','fpr')

plot(perf_logreg_ROC, col=4)
plot(perf_ctree_ROC, add = TRUE, col=7)
plot(perf_svm_ROC, add = TRUE, col = 3)
  legend('topright',
       c('logreg','svm','ctree'),
       fill=topo.colors(3))
```

#Speed Test
```{r}
library(microbenchmark)
library(party)
logreg_spd <- glm(label ~., data = trainData, family = binomial, control = list(maxit = 50))
ctree_spd <- ctree(label ~ ., data = trainData)
svm_spd <- svm(formula = label~., data = trainData, type= "C-classification", kernel = "radial")
speed_test <- microbenchmark('logreg_spd ' = {glm(label ~., data = trainData, family = binomial, control = list(maxit = 50))},
                     'ctree_spd' = {ctree(label ~ ., data = trainData)},
                     'svm_spd' = {svm(formula = label~., data = trainData, type= "C-classification", kernel = "radial")}
)

boxplot(speed_test, unit='ns',log=F,horizontal=T,col=topo.colors(3))
```

#Logistic Regression (with 100% training data)
```{r}
require(foreign)
require(nnet)
require(ggplot2)
require(reshape2)
require(ISLR)
library(caret)
library(e1071)
facial_logreg_full <- glm(label ~., data = Feature_reduction_normalised, family = binomial, control = list(maxit = 50))
summary(facial_logreg_full)
trainPred_logreg_full <- predict(facial_logreg_full, newdata = Feature_reduction_normalised, type = 'response')
logsregPred_full <- ifelse(trainPred_logreg_full > 0.5,1,0)
confusionMatrix(table(logsregPred_full, Feature_reduction_normalised$label))
testPred_logreg <- predict(facial_logreg, newdata = testData, type = 'response')
```

#Classification Tree (with 100% training data)
```{r}
library(party)
Feature_reduction_normalised$label <- as.factor(Feature_reduction_normalised$label)
facial_ctree_full <- ctree(label ~ ., data = Feature_reduction_normalised)
print(facial_ctree_full)
plot(facial_ctree_full, type = 'simple')
plot(facial_ctree_full)
print(facial_ctree_full)
confusionMatrix(table(predict(facial_ctree_full), Feature_reduction_normalised$label))
```