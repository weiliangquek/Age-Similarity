---
title: "DSC3216 Project Codes"
output: 
  html_document:
    toc: yes
---

```{r setup, message = FALSE}
require(foreign)
require(nnet)
require(ggplot2)
require(reshape2)
require(ISLR)
library(caret)
library(party)
library(e1071)
library(gmodels)
library(MLmetrics)
library(ROCR)
```

```{r}
Feature_reduction_normalised <- read.csv("/Users/weiliangquek/OneDrive/Documents/National University of Singapore/AY2018-19 Year 3 Semester 2/DSC3216 Predictive Analytics in Business/Projects/Data/Feature_reduction_normalised.csv")
```

#Create random samples
```{r}
set.seed(123)
train_sample <- sample(nrow(Feature_reduction_normalised),nrow(Feature_reduction_normalised)*0.7)
str(train_sample)
print(train_sample)
trainData <- Feature_reduction_normalised [train_sample,]
testData <- Feature_reduction_normalised [-train_sample,]
```

#Logistic Regression
```{r}
names(Feature_reduction_normalised)
head(Feature_reduction_normalised)
summary(Feature_reduction_normalised)
facial_logreg <- glm(label ~., data = Feature_reduction_normalised, family = binomial, control = list(maxit = 50))
summary(facial_logreg)
trainPred_logreg <- predict(facial_logreg, newdata = trainData, type = 'response')
logsregPred_train <- ifelse(trainPred_logreg > 0.5,1,0)
confusionMatrix(table(logsregPred_train, trainData$label))
testPred_logreg <- predict(facial_logreg, newdata = testData, type = 'response')
logsregPred_test <- ifelse(testPred_logreg > 0.5,1,0)
confusionMatrix(table(logsregPred_test, testData$label))       
```

#Classification Tree 
```{r}
trainData$label <- as.factor(trainData$label)
facial_ctree <- ctree(label ~ ., data = trainData)
print(facial_ctree)
plot(facial_ctree, type = 'simple')
plot(facial_ctree)
table(predict(facial_ctree), trainData$label)
testData$label <- as.factor(testData$label)
facial_ctree_test <- ctree(label ~ ., data = testData)
print(facial_ctree_test)
table(predict(facial_ctree_test), testData$label)
```

#Support Vector Machine (SVM)
```{r}
svm_classifier = svm(formula = label~., data = trainData, type= "C-classification", kernel = "linear")
svm_pred = predict(svm_classifier, newdata= testData)
table(svm_pred, testData$label)
CrossTable(testData$label,svm_pred,prop.chisq= FALSE, prop.c= FALSE, prop.r = FALSE)
confusionMatrix(table(svm_pred, testData$label))
```

#k-fold Cross-Validation (will be using python to get accuracy)
```{r}
set.seed(123) 
train.control <- trainControl(method = "cv", number = 5)
model <- train(label ~., data = Feature_reduction_normalised, method = "lm",
               trControl = train.control)
print(model)
```

#F1-score
```{r}
logreg <- glm(formula = label ~ .,
              family = binomial(link = "logit"), data = Feature_reduction_normalised)
pred <- ifelse(logreg$fitted.values < 0.5, 0, 1)
F1_Score(y_pred = pred, y_true = Feature_reduction_normalised$label, positive = "0")
F1_Score(y_pred = pred, y_true = Feature_reduction_normalised$label, positive = "1")
```

#ROC curve
```{r}
mod <- glm(label~., data=Feature_reduction_normalised, family="binomial")
pred1 <- prediction(predict(mod), Feature_reduction_normalised$label)
perf1 <- performance(pred1,"tpr","fpr")
plot(perf1)
```
